{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:51:18.044772: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import datasets, layers, models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadImages(path, urls,target ):\n",
    "  images = []\n",
    "  labels = []\n",
    "  #for i in range(len(urls))\n",
    "  for i in range(len(urls)):\n",
    "    img_path = path + \"/\" + urls[i]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = img / 255.0\n",
    "    # if we want to resize the images\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    images.append(img)\n",
    "    labels.append(target)\n",
    "  images = np.asarray(images)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "covid_path = \"./data/COVID-19_Radiography_Dataset/COVID/images\"\n",
    "covidUrl = os.listdir(covid_path)\n",
    "covidImages, covidTargets = loadImages(covid_path, covidUrl, 1)\n",
    "\n",
    "normal_path = \"./data/COVID-19_Radiography_Dataset/Normal/images\"\n",
    "normal_urls = os.listdir(normal_path)\n",
    "normalImages, normalTargets = loadImages(normal_path, normal_urls, 0)\n",
    "\n",
    "covidImages=np.asarray(covidImages)\n",
    "\n",
    "normalImages=np.asarray(normalImages)\n",
    "\n",
    "data = np.r_[covidImages, normalImages]\n",
    "\n",
    "targets = np.r_[covidTargets, normalTargets]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, targets, test_size=0.25)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALEXNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 25, 25, 96)        34944     \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 25, 25, 96)        0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 25, 25, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 3, 256)         614656    \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 384)         885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 384)         1327488   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 256)         884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,622,154\n",
      "Trainable params: 21,622,154\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:52:15.958666: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 16:52:16.098259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14786 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.experimental.preprocessing.Resizing(100,100, interpolation=\"bilinear\", input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(layers.Conv2D(96, 11, strides=4, padding='same'))\n",
    "model.add(layers.Lambda(tf.nn.local_response_normalization))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(3, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(256, 5, strides=4, padding='same'))\n",
    "model.add(layers.Lambda(tf.nn.local_response_normalization))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(3, strides=2))\n",
    "\n",
    "model.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(256, 3, strides=4, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-03-06 16:52:34.820528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-03-06 16:52:35.064715: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0xcbde250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-06 16:52:35.064761: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2023-03-06 16:52:35.071449: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-06 16:52:35.209059: I tensorflow/compiler/jit/xla_compilation_cache.cc:480] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 8s 13ms/step - loss: 0.6026 - accuracy: 0.7364 - val_loss: 0.5929 - val_accuracy: 0.7274\n",
      "Epoch 2/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5756 - accuracy: 0.7417 - val_loss: 0.5867 - val_accuracy: 0.7274\n",
      "Epoch 3/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5757 - accuracy: 0.7417 - val_loss: 0.5861 - val_accuracy: 0.7274\n",
      "Epoch 4/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5771 - accuracy: 0.7417 - val_loss: 0.5900 - val_accuracy: 0.7274\n",
      "Epoch 5/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5752 - accuracy: 0.7417 - val_loss: 0.5874 - val_accuracy: 0.7274\n",
      "Epoch 6/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5734 - accuracy: 0.7417 - val_loss: 0.5918 - val_accuracy: 0.7274\n",
      "Epoch 7/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5733 - accuracy: 0.7417 - val_loss: 0.5860 - val_accuracy: 0.7274\n",
      "Epoch 8/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5733 - accuracy: 0.7417 - val_loss: 0.5866 - val_accuracy: 0.7274\n",
      "Epoch 9/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5732 - accuracy: 0.7417 - val_loss: 0.5864 - val_accuracy: 0.7274\n",
      "Epoch 10/10\n",
      "324/324 [==============================] - 3s 10ms/step - loss: 0.5734 - accuracy: 0.7417 - val_loss: 0.5936 - val_accuracy: 0.7274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f065c055220>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10,\n",
    "            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 1s - loss: 0.5936 - accuracy: 0.7274 - 534ms/epoch - 5ms/step\n",
      "Accuracy 0.7274044156074524\n",
      "Loss 0.5935896039009094\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 4ms/step\n",
      "Precision: 0.363702\n",
      "Recall: 0.500000\n",
      "F1 score: 0.421097\n",
      "Jaccard score: 0.363702\n",
      "Cohens kappa: 0.000000\n",
      "[[2511    0]\n",
      " [ 941    0]]\n",
      "[0. 1.] [0. 1.] [1 0]\n",
      "ROC AUC=0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# find accuracy, precision, recall, f1 score, jaccard index, kappa score, confusion matrix, ROC curve, AUC score, etc.\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# jaccard index\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard = jaccard_score(y_test, y_pred, average='macro')\n",
    "print('Jaccard score: %f' % jaccard)\n",
    "\n",
    "# kappa score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(fpr, tpr, thresholds)\n",
    "\n",
    "# AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC=%.3f' % (auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORIGINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = load_model('models/base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "324/324 [==============================] - 6s 11ms/step - loss: 0.0517 - accuracy: 0.9822 - val_loss: 0.0745 - val_accuracy: 0.9757\n",
      "Epoch 2/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 0.0408 - val_accuracy: 0.9846\n",
      "Epoch 3/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.0420 - val_accuracy: 0.9846\n",
      "Epoch 4/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0349 - accuracy: 0.9874 - val_loss: 0.0604 - val_accuracy: 0.9771\n",
      "Epoch 5/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.0541 - val_accuracy: 0.9806\n",
      "Epoch 6/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0251 - accuracy: 0.9902 - val_loss: 0.0563 - val_accuracy: 0.9832\n",
      "Epoch 7/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0631 - val_accuracy: 0.9832\n",
      "Epoch 8/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0591 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.0762 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "324/324 [==============================] - 3s 8ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.0793 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02b81024c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_original.fit(x_train, y_train,epochs=10,validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 0s - loss: 0.0793 - accuracy: 0.9745 - 412ms/epoch - 4ms/step\n",
      "Accuracy 0.9745075106620789\n",
      "Loss 0.0792604386806488\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_original.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_original.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.363702\n",
      "Recall: 0.500000\n",
      "F1 score: 0.421097\n",
      "Jaccard score: 0.363702\n",
      "Cohens kappa: 0.000000\n",
      "[[2511    0]\n",
      " [ 941    0]]\n",
      "[0. 1.] [0. 1.] [1 0]\n",
      "ROC AUC=0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# find accuracy, precision, recall, f1 score, jaccard index, kappa score, confusion matrix, ROC curve, AUC score, etc.\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='macro' , labels=None, pos_label=1, sample_weight=None, zero_division='warn')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# jaccard index\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard = jaccard_score(y_test, y_pred, average='macro')\n",
    "print('Jaccard score: %f' % jaccard)\n",
    "\n",
    "# kappa score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa = cohen_kappa_score(y_test, y_pred , labels=None, weights=None, sample_weight=None)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(fpr, tpr, thresholds)\n",
    "\n",
    "# AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC=%.3f' % (auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(x_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = knn.predict(x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8763035921205099\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.857081\n",
      "Recall: 0.820622\n",
      "F1 score: 0.836017\n",
      "Jaccard score: 0.726658\n",
      "Cohens kappa: 0.672759\n",
      "[[2368  143]\n",
      " [ 284  657]]\n",
      "[0.         0.05694942 1.        ] [0.         0.69819341 1.        ] [2 1 0]\n",
      "ROC AUC=0.821\n"
     ]
    }
   ],
   "source": [
    "# find accuracy, precision, recall, f1 score, jaccard index, kappa score, confusion matrix, ROC curve, AUC score, etc.\n",
    "\n",
    "# precision\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='macro' , labels=None, pos_label=1, sample_weight=None, zero_division='warn')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# jaccard index\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard = jaccard_score(y_test, y_pred, average='macro')\n",
    "print('Jaccard score: %f' % jaccard)\n",
    "\n",
    "# kappa score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa = cohen_kappa_score(y_test, y_pred , labels=None, weights=None, sample_weight=None)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(fpr, tpr, thresholds)\n",
    "\n",
    "# AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC=%.3f' % (auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2511, 1: 941})\n"
     ]
    }
   ],
   "source": [
    "# find class distribution in test set\n",
    "from collections import Counter\n",
    "counter = Counter(y_test)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
